{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# QuPath for Python Programmers üêç\n",
    "**Alan O'Callaghan, L√©o Leplat, Peter Bankhead, Fiona Inglis, Laura Nicol√°s S√°enz**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Introduction/motivation\n",
    "\n",
    "QuPath is user-friendly for analysing large images interactively\n",
    "\n",
    "Python is great for developing and implementing image analysis algorithms with code\n",
    "\n",
    "They don't *always* cooperate nicely... but this is changing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Paquo\n",
    "\n",
    "Paquo is an existing library for QuPath-python\n",
    "interactions.\n",
    "\n",
    "*but* it provides a somewhat \"heavy-weight\" linkage between the two.\n",
    "This is great when you want a well-designed program that uses both languages.\n",
    "\n",
    "QuBaLab aims to be a bit more light-weight, and doesn't aim to provide\n",
    "direct linkage of Java and Python code to the same extent.\n",
    "\n",
    "This means it's good for short experiments, but really not\n",
    "great for complex applications!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cache_folder = \"./i2k-qupath-python-project/images\"\n",
    "\n",
    "# Define a utility function to find or download an image\n",
    "\n",
    "from pathlib import Path\n",
    "import urllib.request\n",
    "\n",
    "if cache_folder != \"\":\n",
    "    Path(cache_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def get_image(image_name, image_url):\n",
    "    if cache_folder == \"\":\n",
    "        filename = None\n",
    "    else:\n",
    "        filename = Path(cache_folder) / image_name\n",
    "    \n",
    "    if filename is None or not(filename.exists()):\n",
    "        print(f\"Downloading {image_name}...\")\n",
    "        path, _ = urllib.request.urlretrieve(image_url, filename=filename)\n",
    "        print(f'{image_name} saved to {path}')\n",
    "    else:\n",
    "        path = filename\n",
    "        print(f'{image_name} found in {path}')\n",
    "\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download or get image\n",
    "cmu_path = get_image(\"CMU-1.svs\", \"https://openslide.cs.cmu.edu/download/openslide-testdata/Aperio/CMU-1.svs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download or get image\n",
    "fluoro_path = get_image(\"patient_test_1.ome.tiff\", \"https://ftp.ebi.ac.uk/biostudies/fire/S-BIAD/463/S-BIAD463/Files/my_submission/Validation_raw/DCIS/Patient_test_1.ome.tiff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## ImageServer\n",
    "\n",
    "QuBaLab provides a number of ImageServers, that allow you to read images\n",
    "just as QuPath would.\n",
    "\n",
    "\n",
    "OpenSlide for RGB images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from qubalab.images.openslide_server import OpenSlideServer\n",
    "\n",
    "print(cmu_path)\n",
    "openslide_server = OpenSlideServer(cmu_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "AICSImageIO for general purpose images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from qubalab.images.aicsimageio_server import AICSImageIoServer\n",
    "\n",
    "print(fluoro_path)\n",
    "aicsimageio_server = AICSImageIoServer(fluoro_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "ICC profile servers that wrap other servers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from qubalab.images.icc_profile_server import IccProfileServer\n",
    "\n",
    "icc_profile_server = IccProfileServer(openslide_server)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "Since we're using an RGB image, we'll use OpenSlide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "server = openslide_server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## ImageServer operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "metadata = server.metadata\n",
    "\n",
    "print(f'Image name: {metadata.name}')\n",
    "print('Levels:')\n",
    "for level, shape in enumerate(metadata.shapes):\n",
    "    print(f'Shape of level {level}: {shape}')\n",
    "print('Pixel calibration:')\n",
    "print(f'Pixel length on x-axis: {metadata.pixel_calibration.length_x}')\n",
    "print(f'Pixel length on y-axis: {metadata.pixel_calibration.length_y}\\n')\n",
    "print(f'Pixel type: {metadata.dtype}')\n",
    "print(f'Downsamples: {metadata.downsamples}\\n')\n",
    "print('Channels:')\n",
    "for channel in metadata.channels:\n",
    "    print(channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Reading images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "highest_downsample = server.metadata.downsamples[-1]\n",
    "lowest_resolution = server.read_region(highest_downsample)\n",
    "\n",
    "print(f'Image shape: {lowest_resolution.shape}')\n",
    "\n",
    "from qubalab.display.plot import plotImage\n",
    "import matplotlib.pyplot as plt\n",
    "_, ax = plt.subplots()\n",
    "plotImage(ax, lowest_resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Reading regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "downsample = 1\n",
    "x = 13000\n",
    "y = 15000\n",
    "width = 2000\n",
    "height = 1000\n",
    "tile = server.read_region(downsample, x=x, y=y, width=width, height=height)\n",
    "\n",
    "print(f'Tile shape: {tile.shape}')\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "plotImage(ax, tile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Reading images lazily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "last_level = server.metadata.n_resolutions - 1\n",
    "lowest_resolution = server.level_to_dask(last_level)\n",
    "\n",
    "# Pixel values are not read yet, but you can get the shape of the image\n",
    "print(f'Image shape: {lowest_resolution.shape}')\n",
    "\n",
    "# Compute array. This will read the pixel values\n",
    "lowest_resolution = lowest_resolution.compute()\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "plotImage(ax, lowest_resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Reading images lazily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "highest_resolution = server.level_to_dask(0)\n",
    "print(f'Full resolution image shape: {highest_resolution.shape}')\n",
    "\n",
    "x = 13000\n",
    "y = 15000\n",
    "width = 2000\n",
    "height = 1000\n",
    "tile = highest_resolution[:, y:y+height, x:x+width]\n",
    "print(f'Tile shape: {tile.shape}')\n",
    "\n",
    "tile = tile.compute() #  This will only read the pixel values of the tile\n",
    "_, ax = plt.subplots()\n",
    "plotImage(ax, tile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Setting up a gateway\n",
    "\n",
    "The main method of interacting with QuPath\n",
    "is through a *gateway*, which operates using\n",
    "a websocket connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from qubalab.qupath import qupath_gateway\n",
    "\n",
    "token = None\n",
    "port = 25333\n",
    "gateway = qupath_gateway.create_gateway(auth_token=token, port=port)\n",
    "\n",
    "gateway"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## QuPath setup\n",
    "\n",
    "We're using a [CC0 TMA image](https://dataverse.harvard.edu/file.xhtml?persistentId=doi:10.7910/DVN/GG0D7G/VCRA28&version=1.0).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(qupath_gateway.create_snapshot())\n",
    "plt.axis(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Basic gateway operations\n",
    "\n",
    "A gateway provides us with an *entry point*,\n",
    "which allows us to call Java methods from python:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Extension version: {gateway.entry_point.getExtensionVersion()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"Current image name: {gateway.entry_point.getCurrentImageName()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Mixing üêç and ‚òï\n",
    "\n",
    "Since the entry point exposes the QuPath scripting interface, you can do lots of basic scripting operations in python by calling object methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "cores = gateway.entry_point.getTMACoreList()\n",
    "\n",
    "tumor_cores = [core for core in cores if core.getClassification() == \"Tumor\"]\n",
    "\n",
    "[(core.getName(), core.getChildObjects().size()) for core in tumor_cores]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Downsides\n",
    "\n",
    "However, it's not ideal to write Java code in python, and we wouldn't necessarily encourage it.\n",
    "\n",
    "If you just want to script QuPath, groovy will\n",
    "remain the best bet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from qubalab.objects.object_type import ObjectType\n",
    "\n",
    "object_type = ObjectType.ANNOTATION    # could be DETECTION, TILE, CELL, TMA_CORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "annotations = qupath_gateway.get_objects(object_type = object_type)\n",
    "annotation = annotations[0]\n",
    "\n",
    "annotation.setName(\"Hello from Python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "qupath_gateway.refresh_qupath()\n",
    "\n",
    "plt.imshow(qupath_gateway.create_snapshot())\n",
    "plt.axis(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Converting objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "annotations = qupath_gateway.get_objects(object_type = object_type, converter='geojson')\n",
    "\n",
    "print(type(annotations[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from shapely.geometry import shape\n",
    "\n",
    "shape(annotations[0].geometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Adding and deleting objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "for annotation in annotations:\n",
    "    annotation.color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "\n",
    "qupath_gateway.add_objects(annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Building a workflow using ImageServer and python\n",
    "\n",
    "Reading the image currently open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from qubalab.images.qupath_server import QuPathServer\n",
    "from skimage.filters import gaussian, threshold_otsu\n",
    "from skimage.color import rgb2gray\n",
    "from qubalab.objects.image_feature import ImageFeature\n",
    "\n",
    "qupath_server = QuPathServer(gateway) # use image currently opened in QuPath\n",
    "downsample = 20 # reduce size by 20x\n",
    "image = qupath_server.read_region(downsample=downsample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Building a workflow using ImageServer and python\n",
    "\n",
    "Converting to grayscale and filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If the image is RGB, we convert it to grayscale\n",
    "# read_region() returns an image with the (c, y, x) shape.\n",
    "# To use rgb2gray, we need to move the channel axis so that\n",
    "# the shape becomes (y, x, c)\n",
    "image = np.moveaxis(image, 0, -1)\n",
    "image = rgb2gray(image)\n",
    "\n",
    "# Apply a gaussian filter\n",
    "image = gaussian(image, 2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Building a workflow\n",
    "- Identify the threshold\n",
    "- Apply the threshold to make a mask\n",
    "- Convert the mask to an image feature\n",
    "- Import the image feature as an annotation\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "threshold = threshold_otsu(image)\n",
    "\n",
    "mask = image < threshold\n",
    "\n",
    "mask_annotation = ImageFeature.create_from_label_image(\n",
    "    mask,   \n",
    "    scale=downsample,   # mask is 20 times smaller than the QuPath image, so we scale\n",
    "                        # the annotations to fit the QuPath image\n",
    "    classification_names=\"Otsu\",  # set a single classification to the detected annotations\n",
    ")\n",
    "qupath_gateway.add_objects(mask_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(mask)\n",
    "plt.title(f'Otsu (threshold={threshold:.2f})')\n",
    "plt.axis(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Other workflow ideas\n",
    "\n",
    "Object classifiers using scikit-learn\n",
    "\n",
    "Object clustering using graph clustering\n",
    "\n",
    "Assessing classifier feature importance\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
